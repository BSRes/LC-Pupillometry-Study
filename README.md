# Pupillometry Analysis for "The Role of Brain Arousal Systems in Prediction and Expectation"

This repository contains the Python scripts and Jupyter Notebooks used for data acquisition, preprocessing, and analysis for the rotation project titled "The Role of Brain Arousal Systems in Prediction and Expectation: A pilot study investigating pupil responses to unexpected stimuli under high vs low attentional load."

## Project Overview

This pilot study investigated whether pupil diameter, an indirect index of Locus Coeruleus (LC) activity, reflects stimulus expectation signals and if such signals are modulated by attentional load. The study involved a visual oddball task with varying attentional demands. Pupil responses were analyzed using a deconvolution General Linear Model (GLM) with a Finite Impulse Response (FIR) model.

## Code Structure

*   **`main.py`**: Main PsychoPy script for running the experiment.
*   **`config.py`**: Configuration file for experimental parameters.
*   **Helper Scripts (`.py` files in the root directory)**: Modules for specific tasks like stimulus generation (`generate_main_stimuli.py`), block planning (`plan_blocks_and_sessions.py`), experimental logic (`block_handler.py`, `run_practice.py`), etc.
*   **Jupyter Notebooks (`.ipynb` files, likely in a `notebooks/` or analysis directory):**
    *   `EDF_Reader.ipynb`: Parses raw EyeLink EDF data into a usable format.
    *   `Data_Preprocessing.ipynb`: Contains steps for cleaning and preprocessing pupil data (artifact rejection, interpolation, filtering).
    *   `Deconvolution.ipynb`: Implements the FIR deconvolution GLM to estimate pupil response functions.
    *   `Data_Analysis_-_Deconvolution_ANOVA.ipynb`: Performs statistical analysis (ANOVA) on the derived beta coefficients.

## Requirements

*   Python 3.x
*   PsychoPy
*   Pandas
*   NumPy
*   SciPy
*   Statsmodels
*   Pingouin
*   Matplotlib
*   Seaborn
*   Pylink (for EyeLink integration)

A `requirements.txt` file may be added in the future for easier environment setup.

## Setup Notes

*   **EyeLink Integration:**
    *   The `EyeLinkCoreGraphicsPsychoPy.py` script, required by `main.py`, is part of the SR Research EyeLink Developer's Kit. It should be placed in the same directory as `main.py` or in your Python path.
    *   Calibration sound files (if used, though currently set to "" in `main.py`) would also typically come from the EyeLink Developer's Kit.
    *   The PyLink folder can also be found in the EyeLink Developer's Kit.
*   **Stimuli:** Main visual stimuli (Gabor patches, noise disk) are generated by `generate_main_stimuli.py` if not already present in the `stimuli_images/` directory (as defined in `config.py`).
*   **Names:** When running the psychopy experiment, the subject is prompted to enter their name. Letters A-Z are expected. Most of the scripts included for extraction, preprocessing, and analysis assume names of 4 repeating letters; "aaaa" - "ffff".

## Usage

1.  **Experiment:** Run `main.py` using PsychoPy to collect data.
2.  **Data Processing & Analysis:** Execute the Jupyter Notebooks in the recommended order:
    1.  `EDF_Reader.ipynb`
    2.  `Data_Preprocessing.ipynb`
    3.  `Deconvolution.ipynb`
    4.  `Data_Analysis_-_Deconvolution_ANOVA.ipynb`

Please ensure all paths in `config.py` and within the notebooks are correctly set for your environment.

## Citation

If you use this code or build upon it in your research, please cite this repository.

Example:
Stallard, Benjamin. (YYYY). *Pupillometry Analysis for "The Role of Brain Arousal Systems in Prediction and Expectation"* (Version X.Y.Z) [Software]. GitHub. https://github.com/BSRes/LC-Pupillometry-Study

Please also consider citing the associated report:
Stallard, B. (YYYY). The Role of Brain Arousal Systems in Prediction and Expectation: A pilot study investigating pupil responses to unexpected stimuli under high vs low attentional load. [Unpublished rotation report]. Royal Holloway, University of London.

## Disclaimer

A lot of this code has been written by hand, while a lot has been generated with AI. Which one is better is likely debatable, but proceed with caution regardless - you'll probably find no end of bugs if you inspect it too closely... For example, there is no way to cancel the experiment once it begins. This is easily solvable by adding in a keyboard event capture with PsychoPy, but I never got around to it.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.
